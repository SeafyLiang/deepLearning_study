{"cells":[{"metadata":{"cell_type":"code","id":"452F7540B9FE40A885B61BA187401D44","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 4-4,AutoGraph的机制原理\n有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。\n\nTensorFlow 2.0主要使用的是动态计算图和Autograph。\n\n动态计算图易于调试，编码效率较高，但执行效率偏低。\n\n静态计算图执行效率很高，但较难调试。\n\n而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。\n\n当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。\n\n我们会介绍Autograph的编码规范和Autograph转换成静态图的原理。\n\n并介绍使用tf.Module来更好地构建Autograph。\n\n上篇我们介绍了Autograph的编码规范，本篇我们介绍Autograph的机制原理。\n\n## 一，Autograph的机制原理\n当我们使用@tf.function装饰一个函数的时候，后面到底发生了什么呢？\n\n例如我们写下如下代码。"},{"metadata":{"id":"35161BA824464C0B9ED209431A7683B7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import tensorflow as tf\nimport numpy as np \n\n@tf.function(autograph=True)\ndef myadd(a,b):\n    for i in tf.range(3):\n        tf.print(i)\n    c = a+b\n    print(\"tracing\")\n    return c","execution_count":1},{"metadata":{"id":"2AC0DFB71C3D4E068B6EAC18322D1FE4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"后面什么都没有发生。仅仅是在Python堆栈中记录了这样一个函数的签名。\n\n**当我们第一次调用这个被@tf.function装饰的函数时，后面到底发生了什么？**\n\n例如我们写下如下代码。"},{"metadata":{"id":"2154CDA59E7840FBA175DAC63838A173","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tracing\n0\n1\n2\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<tf.Tensor: shape=(), dtype=string, numpy=b'helloworld'>"},"transient":{}}],"source":"myadd(tf.constant(\"hello\"),tf.constant(\"world\"))","execution_count":2},{"metadata":{"id":"A34A139DB3B4427A9B4E097ED61767A6","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false},"cell_type":"markdown","source":"发生了2件事情，\n\n第一件事情是创建计算图。\n\n即创建一个静态计算图，跟踪执行一遍函数体中的Python代码，确定各个变量的Tensor类型，并根据执行顺序将算子添加到计算图中。 在这个过程中，如果开启了autograph=True(默认开启),会将Python控制流转换成TensorFlow图内控制流。 主要是将if语句转换成 tf.cond算子表达，将while和for循环语句转换成tf.while_loop算子表达，并在必要的时候添加 tf.control_dependencies指定执行顺序依赖关系。\n\n相当于在 tensorflow1.0执行了类似下面的语句："},{"metadata":{"id":"2BB8267987294E20A19A78741AD7C0AE","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"g = tf.Graph()\nwith g.as_default():\n    a = tf.placeholder(shape=[],dtype=tf.string)\n    b = tf.placeholder(shape=[],dtype=tf.string)\n    cond = lambda i: i<tf.constant(3)\n    def body(i):\n        tf.print(i)\n        return(i+1)\n    loop = tf.while_loop(cond,body,loop_vars=[0])\n    loop\n    with tf.control_dependencies(loop):\n        c = tf.strings.join([a,b])\n    print(\"tracing\")","execution_count":null},{"metadata":{"id":"2C7DC473C4034DB986F482304C68CB46","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false},"cell_type":"markdown","source":"第二件事情是执行计算图。\n\n相当于在 tensorflow1.0中执行了下面的语句："},{"metadata":{"id":"CF7E4952D90342F39E130942A090599C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"with tf.Session(graph=g) as sess:\n    sess.run(c,feed_dict={a:tf.constant(\"hello\"),b:tf.constant(\"world\")})","execution_count":null},{"metadata":{"id":"8B5AC4A28DCA43ADA7BE861DFC82542F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"因此我们先看到的是第一个步骤的结果：即Python调用标准输出流打印\"tracing\"语句。\n\n然后看到第二个步骤的结果：TensorFlow调用标准输出流打印1,2,3。\n\n当我们再次用相同的输入参数类型调用这个被@tf.function装饰的函数时，后面到底发生了什么？\n\n例如我们写下如下代码。"},{"metadata":{"id":"2FED317E746E4943908EC285B886F1A3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"0\n1\n2\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<tf.Tensor: shape=(), dtype=string, numpy=b'goodmorning'>"},"transient":{}}],"source":"myadd(tf.constant(\"good\"),tf.constant(\"morning\"))","execution_count":5},{"metadata":{"id":"3CD763BE2E4C4756BC8B8A3DDCA9B0FA","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"只会发生一件事情，那就是上面步骤的第二步，执行计算图。\n\n所以这一次我们没有看到打印\"tracing\"的结果。\n\n当我们再次用不同的的输入参数类型调用这个被@tf.function装饰的函数时，后面到底发生了什么？\n\n例如我们写下如下代码。"},{"metadata":{"id":"DACE28D0B17D44A3B3322439D90643A5","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tracing\n0\n1\n2\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<tf.Tensor: shape=(), dtype=int32, numpy=3>"},"transient":{}}],"source":"myadd(tf.constant(1),tf.constant(2))","execution_count":6},{"metadata":{"id":"88B6DFAEC25D44F0877E9807719AFBC7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"由于输入参数的类型已经发生变化，已经创建的计算图不能够再次使用。\n\n需要重新做2件事情：创建新的计算图、执行计算图。\n\n所以我们又会先看到的是第一个步骤的结果：即Python调用标准输出流打印\"tracing\"语句。\n\n然后再看到第二个步骤的结果：TensorFlow调用标准输出流打印1,2,3。\n\n需要注意的是，如果调用被@tf.function装饰的函数时输入的参数不是Tensor类型，则每次都会重新创建计算图。\n\n例如我们写下如下代码。两次都会重新创建计算图。因此，一般建议调用@tf.function时应传入Tensor类型。"},{"metadata":{"id":"00575D2E4D464DC280EB568C2E8FBAD7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":true},"cell_type":"code","outputs":[{"output_type":"stream","text":"tracing\n0\n1\n2\ntracing\n0\n1\n2\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"<tf.Tensor: shape=(), dtype=string, numpy=b'goodmorning'>"},"transient":{}}],"source":"myadd(\"hello\",\"world\")\nmyadd(\"good\",\"morning\")","execution_count":7},{"metadata":{"id":"94C75D7187B348998ABCC1BB552D2683","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 二，重新理解Autograph的编码规范\n了解了以上Autograph的机制原理，我们也就能够理解Autograph编码规范的3条建议了。\n\n1，被@tf.function修饰的函数应尽量使用TensorFlow中的函数而不是Python中的其他函数。例如使用tf.print而不是print.\n\n解释：Python中的函数仅仅会在跟踪执行函数以创建静态图的阶段使用，普通Python函数是无法嵌入到静态计算图中的，所以 在计算图构建好之后再次调用的时候，这些Python函数并没有被计算，而TensorFlow中的函数则可以嵌入到计算图中。使用普通的Python函数会导致 被@tf.function修饰前【eager执行】和被@tf.function修饰后【静态图执行】的输出不一致。\n\n2，避免在@tf.function修饰的函数内部定义tf.Variable.\n\n解释：如果函数内部定义了tf.Variable,那么在【eager执行】时，这种创建tf.Variable的行为在每次函数调用时候都会发生。但是在【静态图执行】时，这种创建tf.Variable的行为只会发生在第一步跟踪Python代码逻辑创建计算图时，这会导致被@tf.function修饰前【eager执行】和被@tf.function修饰后【静态图执行】的输出不一致。实际上，TensorFlow在这种情况下一般会报错。\n\n3，被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等数据结构变量。\n\n解释：静态计算图是被编译成C++代码在TensorFlow内核中执行的。Python中的列表和字典等数据结构变量是无法嵌入到计算图中，它们仅仅能够在创建计算图时被读取，在执行计算图时是无法修改Python中的列表或字典这样的数据结构变量的。"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}